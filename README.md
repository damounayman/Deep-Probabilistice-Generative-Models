# Deep-Probabilistice-Generative-Models
In this lab we will discover the principles of a generative model and learn how to build suchmodels in neural networks.

### Lab 1: Variational Auto-Encoders. 
Variational autoencoders (VAEs) are autoencoders that tackle the problem of the latent space irregularity by making the encoder return a distribution over the latent space instead of a single point and by adding in the loss function a regularisation term over that returned distribution in order to ensure a better organisation of the latent space and avoid overfitting.

### Lab 2: Restricted Boltzmann Machine.
The RBM is a two-layered neural networkâ€”the first layer is called the visible layer and the second layer is called the hidden layer. They are called shallow neural networks because they are only two layers deep. In this lab , we coded a Restricted Boltzmann Machine with Gaussian observed random variables
and Bernoulli latent variables.